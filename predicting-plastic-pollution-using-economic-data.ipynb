{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\nIn the last 30 years plastic pollution has quadrupled with roghly 353 tonnes of plastic waste produced globally in 2019 [1]. While the general population is able to mitigate some of the mismanaged plastic waste through reducing, reusing, and recycling, a large amount of plastic waste is produced commercially on a much larger scale. The purpose of this investigation is to use Environmental, Social, and Governance scores of companies, along with other factors such as maritime trading volumes, and GDP per capita to predict the amount of mismanaged plastic polliton in different countries. Models for the analysis were chosen with the [following](#model) in mind. One feature that might have a stronger influence is GDP as countries with a higher GDP might be more careful and manage plastic waste better as to not generate pollution.","metadata":{}},{"cell_type":"markdown","source":"# Setting up\nThe below code contains necessary steps for setting up our machine learning environment. Key features are described in the comments.","metadata":{}},{"cell_type":"code","source":"import warnings \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns # data visualization\nfrom scipy import stats # statistic analysis (e.g. pearson's r correlation)\nfrom sklearn.preprocessing import StandardScaler # data normalisation (chosen over maxmin scaler due to presence of outliers)\nfrom sklearn.model_selection import train_test_split # train test split\n\n#importing models\nfrom sklearn.neighbors import KNeighborsRegressor \nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.model_selection import GridSearchCV # cross-validation for hyperparameter tuning\n\nfrom sklearn.metrics import mean_squared_error as MSE # MSE for error analysis\n\n# getting rid of annoying red messages\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-11-24T11:13:31.006028Z","iopub.execute_input":"2022-11-24T11:13:31.006414Z","iopub.status.idle":"2022-11-24T11:13:31.024539Z","shell.execute_reply.started":"2022-11-24T11:13:31.006380Z","shell.execute_reply":"2022-11-24T11:13:31.023210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Collection and Preperation\nData used included martime trading data, country GDP data, plastic pollution data, and company ESG rating data. All these datasets besides the plastic pollution data provide insight to the commmerical activity of each country. Using this data we hope to find a way to predict for polution through \ncommercial activity data.\n\n\nIn order to work with the data we must first read it into dataframes and clean data for our use.\n\n","metadata":{}},{"cell_type":"code","source":"pd.set_option('display.max_rows', None)\n\n# Setting dataset paths\nm_trading_path = '../input/maritime-trading-volumes/maritime_volume.csv'\np_pollution_path = '../input/plastic-pollution/plastic-pollution.csv'\n#esg_path = '../input/esg-scores-and-ratings/sustainability_scores.csv'\ngdp_path = '../input/world-country-gdp-19602021/world_country_gdp_usd.csv'\ncode_path = '../input/iso-country-codes-global/wikipedia-iso-country-codes.csv'\nregion_path = '../input/country-mapping-iso-continent-region/continents2.csv'\npop_path = '../input/world-population-dataset/world_population.csv'\n\n\n# Reading datasets\nm_trading = pd.read_csv(m_trading_path) #Maritime trading data\np_pollution = pd.read_csv(p_pollution_path) #Plastic pollution by country\n#esg = pd.read_csv(esg_path) #Environmental, social, governance score by company\ngdp = pd.read_csv(gdp_path) #GDP data in USD\nc_code = pd.read_csv(code_path) #Country code data\nregion = pd.read_csv(region_path) #Country region data\npop = pd.read_csv(pop_path) #Population data\n","metadata":{"execution":{"iopub.status.busy":"2022-11-24T11:13:32.980162Z","iopub.execute_input":"2022-11-24T11:13:32.980585Z","iopub.status.idle":"2022-11-24T11:13:33.036393Z","shell.execute_reply.started":"2022-11-24T11:13:32.980549Z","shell.execute_reply":"2022-11-24T11:13:33.035227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Datasets are merged using country code and region as indices","metadata":{}},{"cell_type":"code","source":"# Subsetting and preparing data\ngdp = gdp.iloc[15694:15960,:]\nm_trading = m_trading.iloc[:,[0,1,51]]\nm_trading = m_trading.set_axis([\"Region\",\"stat\",\"trading\"],axis = 1) \nm_trading = m_trading.iloc[1: , :]\nm_trading[\"Region\"] = m_trading[\"Region\"].str.strip() # getting rid of extra spaces\n\n# extracting total trading by region\nm_trading_l = m_trading[m_trading[\"stat\"] == \"Total goods loaded\"]\nm_trading_d = m_trading[m_trading[\"stat\"] == \"Total goods discharged\"]\nm_trading_merged =  m_trading_l.merge(m_trading_d, left_on = \"Region\",right_on = \"Region\")\nm_trading_merged[\"Total Trading\"] = m_trading_merged[\"trading_x\"]+m_trading_merged[\"trading_y\"]\nm_trading_merged = m_trading_merged[[\"Region\",\"Total Trading\"]]\n\npop = pop[[\"CCA3\",\"2020 Population\"]]\n#esg[\"Country\"] = esg[\"Country\"].replace(dict(zip(c_code[\"Alpha-2 code\"],c_code[\"Alpha-3 code\"])))\n\n#mean esg score for all companies by country\n#esg_score = esg.groupby([\"Country\"]).mean().reset_index()\n\n# Merging data\nmerged = gdp.merge(p_pollution,left_on = \"Country Code\",right_on = \"Code\").drop([\"Entity\",\"Code\",\"Year\"],axis = 1)\nmerged = merged.merge(region.iloc[:,[2,5,6]],left_on = \"Country Code\",right_on = \"alpha-3\")\nmerged = merged.merge(m_trading_merged, left_on = \"sub-region\",right_on = \"Region\").drop([\"region\",\"alpha-3\",\"sub-region\"],axis = 1)\nmerged = merged.merge(pop, left_on = \"Country Code\",right_on = \"CCA3\").drop(\"CCA3\",axis = 1)\nmerged = merged.dropna()\nmerged[\"Total mismanaged plastic waste (kg per year)\"] = merged[\"Mismanaged plastic waste to ocean per capita (kg per year)\"] * merged[\"2020 Population\"]\n#merged = merged.merge(esg_score,left_on = \"Country Code\", right_on = \"Country\").drop(\"Country\", axis = 1)\n\n#m_trading_merged.head(300)\n#_pollution.head()\n#esg_score.head()\n#gdp.head()\nmerged","metadata":{"execution":{"iopub.status.busy":"2022-11-24T11:13:34.699985Z","iopub.execute_input":"2022-11-24T11:13:34.700472Z","iopub.status.idle":"2022-11-24T11:13:34.858970Z","shell.execute_reply.started":"2022-11-24T11:13:34.700432Z","shell.execute_reply":"2022-11-24T11:13:34.857706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualisation","metadata":{}},{"cell_type":"code","source":"region = merged.groupby(by=\"Region\").mean()\nsns.scatterplot(region[\"GDP_per_capita_USD\"],merged[\"Mismanaged plastic waste to ocean per capita (kg per year)\"])","metadata":{"execution":{"iopub.status.busy":"2022-11-24T11:15:24.376261Z","iopub.execute_input":"2022-11-24T11:15:24.376734Z","iopub.status.idle":"2022-11-24T11:15:24.624889Z","shell.execute_reply.started":"2022-11-24T11:15:24.376688Z","shell.execute_reply":"2022-11-24T11:15:24.624061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"region = merged.groupby(by=\"Region\").mean()\nsns.scatterplot(region[\"2020 Population\"],region[\"Mismanaged plastic waste to ocean per capita (kg per year)\"])","metadata":{"execution":{"iopub.status.busy":"2022-11-24T11:18:03.782201Z","iopub.execute_input":"2022-11-24T11:18:03.782859Z","iopub.status.idle":"2022-11-24T11:18:03.992232Z","shell.execute_reply.started":"2022-11-24T11:18:03.782795Z","shell.execute_reply":"2022-11-24T11:18:03.991085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting into Training and Testing Data 80% to 20%\n","metadata":{}},{"cell_type":"code","source":"merged_y = merged[\"Total mismanaged plastic waste (kg per year)\"] # getting dependent variable\nmerged = merged.drop([\"Total mismanaged plastic waste (kg per year)\",\"Country Name\", \"Country Code\", \"year\", \"Region\",\"Mismanaged plastic waste to ocean per capita (kg per year)\"], axis = 1) # dropping non-numerical columns and dependent variable\nscaler = StandardScaler() # normalising data\nmerged = scaler.fit_transform(merged)\nmerged_y = scaler.fit_transform(np.reshape(merged_y.values,(-1,1)))                                    \nX_train, X_test, y_train, y_test = train_test_split(merged,merged_y,test_size = 0.2, random_state = 42 )","metadata":{"execution":{"iopub.status.busy":"2022-11-17T04:20:46.977197Z","iopub.execute_input":"2022-11-17T04:20:46.977563Z","iopub.status.idle":"2022-11-17T04:20:47.003891Z","shell.execute_reply.started":"2022-11-17T04:20:46.977531Z","shell.execute_reply":"2022-11-17T04:20:47.002806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing Different Models <a id=\"results\"></a>\n### Model selection <a id=\"model\"></a>\nDue to there being no clear relationship from the data visualisations it seemed like more complex models would work better. There were also no clear splits in the data making regression seem like the better choice over classification.\n### Hyperparameter tuning\nHyperparameters were tuned using grid search cross-validation. By tuning the hyperparameters we were able to reduce the error of each model, therefore increasing performance.\n### Test results\n\n1) Random Forest Regressor 54.8% error\n\n2) KNeighbors Regressor 40.8% error\n\n3) Gradient Boosting Regressor 36-38% error\n\n4) Support Vector Regressor 9.09% error\n\n","metadata":{}},{"cell_type":"code","source":"#Random Forest Regressor (using train data prediction to check if overfitting)\nmodel = RandomForestRegressor(n_estimators = 2000, max_depth = 30, random_state = 18)\nmodel.fit(X_train, y_train)\nprediction = model.predict(X_test)\nprediction2 = model.predict(X_train)\nerror = MSE(y_test,prediction)\nerror2 = MSE(y_train,prediction2)\nrmse = error**.5\nrmse2 = error2**.5\nprint(rmse)\nprint(rmse2)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-11-15T05:44:09.932266Z","iopub.execute_input":"2022-11-15T05:44:09.932616Z","iopub.status.idle":"2022-11-15T05:44:12.407831Z","shell.execute_reply.started":"2022-11-15T05:44:09.932584Z","shell.execute_reply":"2022-11-15T05:44:12.407188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KNeighboors Regressor CV\nleaf_size = list(range(1,50))\nn_neighbors = list(range(1,30))\np=[1,2]\nparam = dict(leaf_size=leaf_size, n_neighbors=n_neighbors, p=p)\nknr = KNeighborsRegressor()\nclf = GridSearchCV(knr, param, cv=10)\nbest = clf.fit(X_train, y_train)\nprint('Best leaf_size:', best.best_estimator_.get_params()['leaf_size'])\nprint('Best p:', best.best_estimator_.get_params()['p'])\nprint('Best n_neighbors:', best.best_estimator_.get_params()['n_neighbors'])","metadata":{"execution":{"iopub.status.busy":"2022-11-15T05:44:15.531698Z","iopub.execute_input":"2022-11-15T05:44:15.532255Z","iopub.status.idle":"2022-11-15T05:44:53.822872Z","shell.execute_reply.started":"2022-11-15T05:44:15.532221Z","shell.execute_reply":"2022-11-15T05:44:53.821931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KNeighboors Regressor\nmodel2 = KNeighborsRegressor(leaf_size = 1, p = 2, n_neighbors=27)\nmodel2.fit(X_train, y_train)\npred = model2.predict(X_test)\nerror3 = MSE(y_test,pred)\nrmse3 = error3**.5\nprint(rmse3)","metadata":{"execution":{"iopub.status.busy":"2022-11-15T06:34:41.067398Z","iopub.execute_input":"2022-11-15T06:34:41.067856Z","iopub.status.idle":"2022-11-15T06:34:41.075634Z","shell.execute_reply.started":"2022-11-15T06:34:41.067814Z","shell.execute_reply":"2022-11-15T06:34:41.074244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Gradient Boosting Regressor\nerrors = 0\nfor i in range(100):\n    model3 = GradientBoostingRegressor(learning_rate= 0.02, max_depth= 6, n_estimators= 100, subsample= 0.1)\n    model3.fit(X_train, y_train)\n    predict = model3.predict(X_test)\n    error = MSE(y_test,predict)\n    rmse = error**.5\n    errors += rmse\nprint(f\"average rmse :{errors/100}\") #Average error over 100 trials because bagging is random.","metadata":{"execution":{"iopub.status.busy":"2022-11-15T06:53:17.75474Z","iopub.execute_input":"2022-11-15T06:53:17.755274Z","iopub.status.idle":"2022-11-15T06:53:20.229023Z","shell.execute_reply.started":"2022-11-15T06:53:17.755225Z","shell.execute_reply":"2022-11-15T06:53:20.22836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Gradient Boosting Regressor CV \nparameters = {'learning_rate': [0.01,0.02,0.03,0.04],\n                  'subsample'    : [0.9, 0.5, 0.2, 0.1],\n                  'n_estimators' : [100,500,1000, 1500],\n                  'max_depth'    : [4,6,8,10]\n              }\nGBR = GradientBoostingRegressor()\n\ngrid_GBR = GridSearchCV(estimator=GBR, param_grid = parameters, cv = 2, n_jobs=-1)\ngrid_GBR.fit(X_train, y_train)\nprint(\" Results from Grid Search \" )\nprint(\"\\n The best estimator across ALL searched params:\\n\",grid_GBR.best_estimator_)\nprint(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\nprint(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-11-15T06:52:01.876988Z","iopub.execute_input":"2022-11-15T06:52:01.877292Z","iopub.status.idle":"2022-11-15T06:52:43.803415Z","shell.execute_reply.started":"2022-11-15T06:52:01.877263Z","shell.execute_reply":"2022-11-15T06:52:43.802488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Support Vector Regressor \nmodel = SVR(C= 10, epsilon= 0.1, gamma= 1e-07, kernel= 'rbf')\nmodel.fit(X_train, y_train)\nprediction = model.predict(X_test)\nerror = MSE(y_test,prediction)\nrmse = error**.5\nprint(rmse)\n","metadata":{"execution":{"iopub.status.busy":"2022-11-15T05:49:09.528849Z","iopub.execute_input":"2022-11-15T05:49:09.529215Z","iopub.status.idle":"2022-11-15T05:49:09.537724Z","shell.execute_reply.started":"2022-11-15T05:49:09.529175Z","shell.execute_reply":"2022-11-15T05:49:09.536253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Support Vector Regressor CV \nparameters = {'kernel': ('linear', 'rbf','poly'), 'C':[1.5, 10],'gamma': [1e-7, 1e-4],'epsilon':[0.1,0.2,0.5,0.3]}\nSVR_Grid = GridSearchCV(model, parameters)\nSVR_Grid.fit(X_train,y_train)\nSVR_Grid.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-11-15T05:49:08.580393Z","iopub.execute_input":"2022-11-15T05:49:08.580705Z","iopub.status.idle":"2022-11-15T05:49:09.014865Z","shell.execute_reply.started":"2022-11-15T05:49:08.580677Z","shell.execute_reply":"2022-11-15T05:49:09.013954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Conclusion\nThe purpose of this investigation was to take different aspects of a country's economic activity to predict the amount of mismanaged plastic waste produced. Through this invesitgation, we were able to predict the amount of mismanaged plastic waste by a country within a 9.1% error. Because the data was normalised using a standard scaler to be between 0 and 1. Any error found using techniques such as RMSE are in % error. The final model chosen is a Support Vector Regression model. This model seems to preform reasonably well for the amount of data it is trained with, and much better than the other models that were [tested.](#results) This could be due to the model being sophisticated enough to fit the data, therefore reducing bias and being able to predict better.\n\n\n   \n\n# Future Work\nAlthough this model is able predict with a relatively low error of 9%, it can still be improved. One way the model could be improved is through adding more data. The amount of variables that are used to train the dataset are quite small. It would also help to test for statistically significant variables before training the model. With a greater understaning of how the hyperparameters for Support Vector Regression works, each model could also be tuned with more detail in order to increase accuracy.\n\n\n\n# References\n1) Plastic pollution is growing relentlessly as waste management and recycling fall short, says OECD. (n.d.). Www.oecd.org. Retrieved November 15, 2022, from https://www.oecd.org/newsroom/plastic-pollution-is-growing-relentlessly-as-waste-management-and-recycling-fall-short.htm#:~:text=There%20is%20now%20an%20estimated\n\nPython and Machine Learning Courses on [Datacamp.com](http://www.datacamp.com/)\n- [Introduction to Python](https://app.datacamp.com/learn/courses/intro-to-python-for-data-science)\n- [Intermediate Python](https://app.datacamp.com/learn/courses/intermediate-python)\n- [Supervised Learning with scikit-learn](https://app.datacamp.com/learn/courses/supervised-learning-with-scikit-learn)\n- [Machine Learning with Tree-Based Models in Python](https://app.datacamp.com/learn/courses/machine-learning-with-tree-based-models-in-python)\n\n\n\n","metadata":{}}]}